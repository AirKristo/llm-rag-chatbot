{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<h1>BDS HW Solution: Building a ChatBot</h1>"
   ],
   "metadata": {
    "id": "b3lgj1SZDOU-"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create a virtual environment if you are running this locally<br>\n",
    "Install and import other packages if required"
   ],
   "metadata": {
    "id": "QSU-6Wd58Qnx"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install -qU pymupdf\n",
    "!pip install -qU langchain-community\n",
    "!pip install -qU langchain-google-genai\n",
    "!pip install -qU langchain-text-splitters\n",
    "!pip install -qU \"langchain-chroma>=0.1.2\""
   ],
   "metadata": {
    "id": "WDY_5klI79aw",
    "ExecuteTime": {
     "end_time": "2025-03-23T23:53:25.502743Z",
     "start_time": "2025-03-23T23:52:46.538576Z"
    }
   },
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import fitz  # PyMuPDF\n",
    "import nltk\n",
    "import json\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import pipeline, AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import PromptTemplate"
   ],
   "metadata": {
    "id": "CDGix4iD8NSM",
    "ExecuteTime": {
     "end_time": "2025-03-23T23:56:40.188879Z",
     "start_time": "2025-03-23T23:56:40.184604Z"
    }
   },
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')"
   ],
   "metadata": {
    "id": "uf4QagUF8M16",
    "ExecuteTime": {
     "end_time": "2025-03-23T23:56:44.661457Z",
     "start_time": "2025-03-23T23:56:44.055152Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/kristop/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/kristop/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Task 1"
   ],
   "metadata": {
    "id": "3BZIaQ1wH8CZ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# TODO: Download zip file and Unzip to get all PDFs for the chatbot knowledge base\n",
    "!unzip Docs.zip\n",
    "folder_name = \"Docs\""
   ],
   "metadata": {
    "id": "YWCDvCXmH8CZ",
    "ExecuteTime": {
     "end_time": "2025-03-23T23:57:37.518406Z",
     "start_time": "2025-03-23T23:57:37.119121Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  Docs.zip\r\n",
      "   creating: Docs/\r\n",
      "  inflating: Docs/Searchfor_Barwick.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._Searchfor_Barwick.pdf  \r\n",
      "  inflating: Docs/Commentson_Szpak.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._Commentson_Szpak.pdf  \r\n",
      "  inflating: Docs/CoherentNuclear_Vaidya.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._CoherentNuclear_Vaidya.pdf  \r\n",
      "  inflating: Docs/DeuteronWaves_Yabuuchi.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._DeuteronWaves_Yabuuchi.pdf  \r\n",
      "  inflating: Docs/Electrolysisof_Warner.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._Electrolysisof_Warner.pdf  \r\n",
      "  inflating: Docs/Inthe_Storms.pdf   \r\n",
      "  inflating: __MACOSX/Docs/._Inthe_Storms.pdf  \r\n",
      "  inflating: Docs/ConcentrationPolarization_Barbieri.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._ConcentrationPolarization_Barbieri.pdf  \r\n",
      "  inflating: Docs/Possibilityof_Zhang.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._Possibilityof_Zhang.pdf  \r\n",
      "  inflating: Docs/ColdFusion_Arata2.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._ColdFusion_Arata2.pdf  \r\n",
      "  inflating: Docs/Fulgurites,Boludes,_Andrianov.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._Fulgurites,Boludes,_Andrianov.pdf  \r\n",
      "  inflating: Docs/Corroboratingevidence_Arata.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._Corroboratingevidence_Arata.pdf  \r\n",
      "  inflating: Docs/Criticalcondition_Arata.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._Criticalcondition_Arata.pdf  \r\n",
      "  inflating: Docs/InternalConversion_Yu.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._InternalConversion_Yu.pdf  \r\n",
      "  inflating: Docs/Presenceof_Arata.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._Presenceof_Arata.pdf  \r\n",
      "  inflating: Docs/AnomalousCalorimetric_Appleby.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._AnomalousCalorimetric_Appleby.pdf  \r\n",
      "  inflating: Docs/ASearch_Bartalucci.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._ASearch_Bartalucci.pdf  \r\n",
      "  inflating: Docs/.DS_Store          \r\n",
      "  inflating: __MACOSX/Docs/._.DS_Store  \r\n",
      "  inflating: Docs/NaturalLow_Andrianov.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._NaturalLow_Andrianov.pdf  \r\n",
      "  inflating: Docs/Steadyconcentration_Zhang.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._Steadyconcentration_Zhang.pdf  \r\n",
      "  inflating: Docs/Pinchedcavitation_Stringham.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._Pinchedcavitation_Stringham.pdf  \r\n",
      "  inflating: Docs/StormsEastudentsg.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._StormsEastudentsg.pdf  \r\n",
      "  inflating: Docs/Investigationof_Baranowski.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._Investigationof_Baranowski.pdf  \r\n",
      "  inflating: Docs/Studyof_Aoki.pdf   \r\n",
      "  inflating: __MACOSX/Docs/._Studyof_Aoki.pdf  \r\n",
      "  inflating: Docs/ColdFusion_Takahashi.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._ColdFusion_Takahashi.pdf  \r\n",
      "  inflating: Docs/TheLatest_Zaromb.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._TheLatest_Zaromb.pdf  \r\n",
      "  inflating: Docs/Anomalousproduction_Arata.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._Anomalousproduction_Arata.pdf  \r\n",
      "  inflating: Docs/ThermodynamicPrediction_Tashyrev.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._ThermodynamicPrediction_Tashyrev.pdf  \r\n",
      "  inflating: Docs/Anomalousenhancement_Yuki.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._Anomalousenhancement_Yuki.pdf  \r\n",
      "  inflating: Docs/NuclearReactions_Hale.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._NuclearReactions_Hale.pdf  \r\n",
      "  inflating: Docs/ColdFusion_Yang.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._ColdFusion_Yang.pdf  \r\n",
      "  inflating: Docs/Potentiallyexplosive_Andresen.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._Potentiallyexplosive_Andresen.pdf  \r\n",
      "  inflating: Docs/Letterto_Miles.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._Letterto_Miles.pdf  \r\n",
      "  inflating: Docs/NewTechnique_Uchikawa.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._NewTechnique_Uchikawa.pdf  \r\n",
      "  inflating: Docs/SevenChemical_Bockris.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._SevenChemical_Bockris.pdf  \r\n",
      "  inflating: Docs/Anomalous'deuterium-reaction_Arata.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._Anomalous'deuterium-reaction_Arata.pdf  \r\n",
      "  inflating: Docs/Calorimetry,Neutron_Lewis.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._Calorimetry,Neutron_Lewis.pdf  \r\n",
      "  inflating: Docs/Metallurgicaleffects_Violante.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._Metallurgicaleffects_Violante.pdf  \r\n",
      "  inflating: Docs/Precisionand_Miles.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._Precisionand_Miles.pdf  \r\n",
      "  inflating: Docs/FieldFormation_Tamaki.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._FieldFormation_Tamaki.pdf  \r\n",
      "  inflating: Docs/Detectionof_Taniguchi.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._Detectionof_Taniguchi.pdf  \r\n",
      "  inflating: Docs/ACatalytic_Teller.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._ACatalytic_Teller.pdf  \r\n",
      "  inflating: Docs/AnomalousPhenomena_Wang.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._AnomalousPhenomena_Wang.pdf  \r\n",
      "  inflating: Docs/Achievementof_Arata.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._Achievementof_Arata.pdf  \r\n",
      "  inflating: Docs/Anew_Arata_2.pdf   \r\n",
      "  inflating: __MACOSX/Docs/._Anew_Arata_2.pdf  \r\n",
      "  inflating: Docs/Effectsof_Zhang_2.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._Effectsof_Zhang_2.pdf  \r\n",
      "  inflating: Docs/AnObituary_Veziroglu.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._AnObituary_Veziroglu.pdf  \r\n",
      "  inflating: Docs/ProbableProducts_Andrianov.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._ProbableProducts_Andrianov.pdf  \r\n",
      "  inflating: Docs/Behaviourof_Bertalot.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._Behaviourof_Bertalot.pdf  \r\n",
      "  inflating: Docs/SPAWARSystems_Szpak.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._SPAWARSystems_Szpak.pdf  \r\n",
      "  inflating: Docs/StormsEexplaining.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._StormsEexplaining.pdf  \r\n",
      "  inflating: Docs/Fusaoa_Storms.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._Fusaoa_Storms.pdf  \r\n",
      "  inflating: Docs/Conditionsand_Vysotskii.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._Conditionsand_Vysotskii.pdf  \r\n",
      "  inflating: Docs/TechnologyForecast:_Barnhart.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._TechnologyForecast:_Barnhart.pdf  \r\n",
      "  inflating: Docs/Changesof_Barton.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._Changesof_Barton.pdf  \r\n",
      "  inflating: Docs/Structuralanalysis_Arachi.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._Structuralanalysis_Arachi.pdf  \r\n",
      "  inflating: Docs/Effectsof_Zhang.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._Effectsof_Zhang.pdf  \r\n",
      "  inflating: Docs/NuclearProducts_Miley.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._NuclearProducts_Miley.pdf  \r\n",
      "  inflating: Docs/Responseto_Storms.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._Responseto_Storms.pdf  \r\n",
      "  inflating: Docs/Whatis_Storms.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._Whatis_Storms.pdf  \r\n",
      "  inflating: Docs/Definitivedifference_Arata.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._Definitivedifference_Arata.pdf  \r\n",
      "  inflating: Docs/Deuteriumnuclear_Arata.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._Deuteriumnuclear_Arata.pdf  \r\n",
      "  inflating: Docs/Experimentalobservation_Arapi.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._Experimentalobservation_Arapi.pdf  \r\n",
      "  inflating: Docs/Commenton_Tsirlin.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._Commenton_Tsirlin.pdf  \r\n",
      "  inflating: Docs/Searchfor_Aoki.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._Searchfor_Aoki.pdf  \r\n",
      "  inflating: Docs/MolecularDynamics_Richards.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._MolecularDynamics_Richards.pdf  \r\n",
      "  inflating: Docs/RemarksMade_Bray.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._RemarksMade_Bray.pdf  \r\n",
      "  inflating: Docs/TheStructure_Anderson.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._TheStructure_Anderson.pdf  \r\n",
      "  inflating: Docs/Highlyreliable_Aoyama.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._Highlyreliable_Aoyama.pdf  \r\n",
      "  inflating: Docs/Theory(Topical_Baym.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._Theory(Topical_Baym.pdf  \r\n",
      "  inflating: Docs/HydrogenDeuteriumLoading_Azzarone.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._HydrogenDeuteriumLoading_Azzarone.pdf  \r\n",
      "  inflating: Docs/Mechanismof_Tsuchiya.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._Mechanismof_Tsuchiya.pdf  \r\n",
      "  inflating: Docs/TheSolubility_Antonov.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._TheSolubility_Antonov.pdf  \r\n",
      "  inflating: Docs/Remarksof_Teller.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._Remarksof_Teller.pdf  \r\n",
      "  inflating: Docs/GroupsReporting_Will.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._GroupsReporting_Will.pdf  \r\n",
      "  inflating: Docs/Anew_Arata.pdf     \r\n",
      "  inflating: __MACOSX/Docs/._Anew_Arata.pdf  \r\n",
      "  inflating: Docs/ConditionsLeading_Gajda.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._ConditionsLeading_Gajda.pdf  \r\n",
      "  inflating: Docs/D+_Yuki.pdf        \r\n",
      "  inflating: __MACOSX/Docs/._D+_Yuki.pdf  \r\n",
      "  inflating: Docs/D-D(H-H)_White.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._D-D(H-H)_White.pdf  \r\n",
      "  inflating: Docs/Achievementof_Arata_2.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._Achievementof_Arata_2.pdf  \r\n",
      "  inflating: Docs/ElectrochemicalExperiments_Ziegler.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._ElectrochemicalExperiments_Ziegler.pdf  \r\n",
      "  inflating: Docs/NewHydrogen_Vigier.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._NewHydrogen_Vigier.pdf  \r\n",
      "  inflating: Docs/What_Is_Cold_Fusion_and_Why_Should_You_C.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._What_Is_Cold_Fusion_and_Why_Should_You_C.pdf  \r\n",
      "  inflating: Docs/Theonly_Bass.pdf   \r\n",
      "  inflating: __MACOSX/Docs/._Theonly_Bass.pdf  \r\n",
      "  inflating: Docs/NeutronDetection:_Angelone.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._NeutronDetection:_Angelone.pdf  \r\n",
      "  inflating: Docs/ExperimentalEvidence_Bertin.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._ExperimentalEvidence_Bertin.pdf  \r\n",
      "  inflating: Docs/Cold'fusion_Arata.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._Cold'fusion_Arata.pdf  \r\n",
      "  inflating: Docs/Nuclearfusion_Wada.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._Nuclearfusion_Wada.pdf  \r\n",
      "  inflating: Docs/Electrochemicaleffects_Zhang.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._Electrochemicaleffects_Zhang.pdf  \r\n",
      "  inflating: Docs/MaterialBehavior_Asami.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._MaterialBehavior_Asami.pdf  \r\n",
      "  inflating: Docs/ThePd-Pt-H_Antonov.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._ThePd-Pt-H_Antonov.pdf  \r\n",
      "  inflating: Docs/Coldfusion_Arata.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._Coldfusion_Arata.pdf  \r\n",
      "  inflating: Docs/Preliminaryobservations_Antanasijevic.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._Preliminaryobservations_Antanasijevic.pdf  \r\n",
      "  inflating: Docs/Whatis_Storms_2.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._Whatis_Storms_2.pdf  \r\n",
      "  inflating: Docs/ExcessHeat_Yeager.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._ExcessHeat_Yeager.pdf  \r\n",
      "  inflating: Docs/MassSpectrometry:_Apicella.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._MassSpectrometry:_Apicella.pdf  \r\n",
      "  inflating: Docs/ColdFusion_Storms.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._ColdFusion_Storms.pdf  \r\n",
      "  inflating: Docs/OnBose-Einstein_Vaidya.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._OnBose-Einstein_Vaidya.pdf  \r\n",
      "  inflating: Docs/CheckList_Nagel.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._CheckList_Nagel.pdf  \r\n",
      "  inflating: Docs/GorskyEffect_Verbruggen.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._GorskyEffect_Verbruggen.pdf  \r\n",
      "  inflating: Docs/Arethere_Zhang.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._Arethere_Zhang.pdf  \r\n",
      "  inflating: Docs/Searchfor_Myers.pdf  \r\n",
      "  inflating: __MACOSX/Docs/._Searchfor_Myers.pdf  \r\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "  \"\"\"Extracts text from a PDF file.\"\"\"\n",
    "  doc = fitz.open(pdf_path)\n",
    "  text = \"\\n\".join([page.get_text() for page in doc])\n",
    "  return text\n",
    "\n",
    "def process_pdf(pdf_path, output_txt):\n",
    "  \"\"\"Extracts text and saves the result.\"\"\"\n",
    "  text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "  with open(output_txt, 'w', encoding='utf-8') as f:\n",
    "      f.write(text)\n",
    "\n",
    "\n",
    "# TODO: Create a directory to store the extracted text\n",
    "os.mkdir(\"Docs_Txt\")\n",
    "\n",
    "# TODO: Use the given functions to extract text from all PDFs in the zip file and save it as a .txt file with the same filename\n",
    "for fl in os.listdir(\"Docs\"):\n",
    "  if \".pdf\" in fl:\n",
    "    process_pdf(f\"Docs/{fl}\", f\"Docs_Txt/{fl.split('.')[0]}.txt\")"
   ],
   "metadata": {
    "id": "1MV6sICh9Q5L",
    "ExecuteTime": {
     "end_time": "2025-03-24T00:38:12.956101Z",
     "start_time": "2025-03-24T00:38:11.051123Z"
    }
   },
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jWSZq9DsH8CZ",
    "ExecuteTime": {
     "end_time": "2025-03-24T00:38:18.798829Z",
     "start_time": "2025-03-24T00:38:14.449207Z"
    }
   },
   "source": [
    "def chunk_text(text, chunk_size):\n",
    "  \"\"\"Splits text into chunks of approximately `chunk_size` words.\"\"\"\n",
    "  words = nltk.word_tokenize(text)\n",
    "  chunks = [\" \".join(words[i:i+chunk_size]) for i in range(0, len(words), chunk_size)]\n",
    "  return chunks\n",
    "\n",
    "def generate_embeddings(model, chunks):\n",
    "  \"\"\"Generates embeddings for text chunks.\"\"\"\n",
    "  return model.encode(chunks).tolist()\n",
    "\n",
    "\n",
    "# TODO: Initialize any text embedding model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# TODO: For each given PDF:\n",
    "# 1. Read the extracted .txt file\n",
    "# 2. Create chunks of any size\n",
    "# 3. Append to a list the chunk, its embedding and the filename\n",
    "# Utilize the functions provided above\n",
    "embeddings_list = []\n",
    "\n",
    "for fl in os.listdir(\"Docs\")[:10]:\n",
    "  if \".pdf\" not in fl:\n",
    "    continue\n",
    "  text = \"\" # Read the associated .txt file\n",
    "  with open(\"Docs_Txt/\"+fl.split(\".\")[0]+\".txt\", 'r', encoding='utf-8') as f:\n",
    "      text = f.read()\n",
    "\n",
    "  chunks = chunk_text(text, 256) # Creating chunks of size N\n",
    "\n",
    "  for ch in chunks:\n",
    "    embeds = generate_embeddings(model, [chunks]) # Generate embeddings for each chunk\n",
    "    embeddings_list.append({\n",
    "      \"embedding\": embeds[0],\n",
    "      \"chunk\": ch,\n",
    "      \"filename\": fl\n",
    "  })\n",
    "\n",
    "\n",
    "with open(\"KnowledgeBase.json\", 'w', encoding='utf-8') as f:\n",
    "        json.dump(embeddings_list, f, indent=4)"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Task 2"
   ],
   "metadata": {
    "id": "QigZ9jCkA2YA"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "query1 = \"Who is the founder of NYU?\""
   ],
   "metadata": {
    "id": "NCXuCgEeA6Zg",
    "ExecuteTime": {
     "end_time": "2025-03-24T00:38:54.036364Z",
     "start_time": "2025-03-24T00:38:54.034660Z"
    }
   },
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": [
    "# TODO: Generate text embedding for the query with the same model use previously\n",
    "query_embedding = model.encode([query1]).tolist()"
   ],
   "metadata": {
    "id": "PaBpzLs_A-k8",
    "ExecuteTime": {
     "end_time": "2025-03-24T00:38:56.604170Z",
     "start_time": "2025-03-24T00:38:56.260077Z"
    }
   },
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": [
    "# TODO: Define function to return the n most similar chunks from a Knowledge Base json file, when given a query embedding\n",
    "# 1. Read from JSON file to get a list of all chunks\n",
    "# 2. Use the cosine similarity function to compute similarity scores between the query and all chunks\n",
    "# 3. Return the top n most similar embeddings with the chunk text and filename\n",
    "\n",
    "def find_similar_chunks(query_embed, json_file, embedding_model, top_n):\n",
    "  \"\"\"Finds the top N most similar text chunks to the query.\"\"\"\n",
    "  with open(json_file, 'r', encoding='utf-8') as f:\n",
    "      data = json.load(f)\n",
    "\n",
    "  chunk_embeddings = np.array([item[\"embedding\"] for item in data])\n",
    "  similarities = cosine_similarity(query_embed, chunk_embeddings)[0]\n",
    "\n",
    "  top_n_indices = np.argsort(similarities)[-top_n:][::-1]\n",
    "  return [data[i] for i in top_n_indices]"
   ],
   "metadata": {
    "id": "TIsy8hbUH8Ca",
    "ExecuteTime": {
     "end_time": "2025-03-24T00:39:07.485470Z",
     "start_time": "2025-03-24T00:39:07.482381Z"
    }
   },
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "source": [
    "# Prints the top 5 documents for the given 'query1'\n",
    "\n",
    "top_results = find_similar_chunks(query_embedding, \"KnowledgeBase.json\", model, top_n=5)\n",
    "for result in top_results:\n",
    "  print(f'{result[\"filename\"]}: {result[\"chunk\"]}')"
   ],
   "metadata": {
    "id": "gP860XuWH8Ca",
    "ExecuteTime": {
     "end_time": "2025-03-24T00:39:09.840055Z",
     "start_time": "2025-03-24T00:39:09.771594Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inthe_Storms.pdf: Chem . 270 ( 1989 ) 451 . [ 4 ] J.O.M . Bockris , Accountability and academic freedom : The battle concerning research on cold fusion at Texas A & M Univer- sity , Accountability in Res . 8 ( 2000 ) 103–119 .\n",
      "Inthe_Storms.pdf: does not make a person rational . Nevertheless , we all need to be reminded that new ideas must be considered with humility , objectivity , and knowledge , especially in the ﬁeld of cold fusion itself . Some new ideas are clearly wrong and need to be identiﬁed and improved . How this needs to be done is well understood in science . It does not and must not involve personal attack . Every kid who dreams of being a scientist knows this , so why is something so basic forgotten by some working scientists . Ideas must be evaluated by logic and knowledge . The rest of us need to keep reminding those scientists who forget how they are supposed to behave , as John would have wanted . References [ 1 ] M. Fleischmann , S. Pons and M. Hawkins , Electrochemically induced nuclear fusion of deuterium , J. Electroanal . Chem . 261 ( 1989 ) 301–308 and errata in 263 ( 1989 ) 187–188 . [ 2 ] R.C . Kainthla , O.A . Velev , L. Kaba , G.H . Lin , N.J.C . Packham , M. Szklarczyk , J. Wass and J.O.M . Bockris , Sporadic obser- vation of the Fleischmann–Pons heat effect , Electrochim . Acta 34 ( 1989 ) 1315 . [ 3 ] N.J.C . Packham , K.L . Wolf , J.C. Wass , R.C . Kainthla and J.O.M . Bockris , Production of tritium from D2O electrolysis at a palladium cathode , J. Electroanal .\n",
      "Inthe_Storms.pdf: E. Storms / Journal of Condensed Matter Nuclear Science 16 ( 2015 ) 8–9 9 now the phenomenon has been proven real by overwhelming evidence . The skeptics and the small-minded attackers were proven wrong . Profs . Fleishmann and Pons have been vindicated . Only self-imposed ignorance now stops conventional science from accepting this fact . You might wonder what this sorry tale has to do with John ’ s life and death . John ’ s life was devoted to teaching science at the highest level of competence and integrity . When he experienced the hostile treatment allowed by his university and the rejection by people he considered friends , he was naturally surprised , disappointed , and ﬁnally became angry . He spoke out in a paper describing the experience [ 4 ] . While his death stopped his ability to teach the proper way to have a scientiﬁc discussion , we the living have the responsibility to do the job . We all suffer the occasional consequence of ignorant and small minded behavior , but when a famous person of high standards and obvious competence , such as Profs . Bockris , Fleischmann , and Pons , are treated this way by the scientiﬁc society in general , a serious re-examination of scientiﬁc standards is required . Apparently , this process has to be undertaken in every ﬁeld of science by every generation because the arrogance of the human mind is never cured , self-interest always trumps truth , and being smart\n",
      "Inthe_Storms.pdf: at the University of Texas where he taught questioned his motives , honesty , and competence . This attack resulted in he and his wife being rejected by “ friends ” , an effort was made to strip him of his honor as Distinguished Professor , and the resulting legal problems required the services of a lawyer . The ﬁnancial and emotional consequences took a toll on him and his family . Meanwhile , Martin Fleischmann and Stanley Pons were experiencing similar irrational personal attack , requiring Martin to return to England and Stan to immigrate permanently to France with his family , where they were not sub- jected to such harsh treatment . While these three famous people provide examples of the most egregious irrational response to the discovery , almost every one who dared to study or advocate for the idea suffered . In addition to per- sonal attack , certain powerful scientists created a myth by claiming the conclusions were not real , were an example of bad science , and were not worth the attention of anyone who valued their scientiﬁc career . Over the next 25 years , the subject was largely hidden from the general public and conventional science . Major journals refused publication of papers , professors refused to encourage student interest , and ﬁnancial support was denied by the effective policy of the DOE . Nevertheless , information about the unusual behavior accumulated until ∗E-mail : storms2 @ ix.netcom.com c⃝2015 ISCMNS . All rights reserved . ISSN 2227-3123\n",
      "Inthe_Storms.pdf: J. Condensed Matter Nucl . Sci . 16 ( 2015 ) 8–9 Obituary Note In the Spirit of John Bockris Edmund Storms∗ 2140 Paseo Ponderosa , Santa Fe , NM 87501 , USA Abstract The life of Prof. John Bockris provides a reminder of how good science should be undertaken and the harm a scientist and all of science suffer when these expectations are ignored . c⃝2015 ISCMNS . All rights reserved . ISSN 2227-3123 Keywords : Electrochemistry , John Bockris , Palladium , Transmutation , Tritium The spirit of Bernhardt Patrick John ÓMara Bockris left this world on July 7 , 2013 after spending 90 years teach- ing us all how to be creative , mainly in electrochemistry , but most recently in cold fusion . He , along with Martin Fleischmann , provided our modern understanding of electrochemistry , for which he was rewarded with fame and ad- miration . If he had done nothing else , he would be remembered as an effective teacher , a good friend , and an example of the highest achievement in science . But John went further by having the courage to study what is known as cold fusion . Thanks to his knowledge of electrochemistry and his friendship with Martin Fleischmann , who along with Stanley Pons [ 1 ] , discovered the phenomenon , he was one of the ﬁrst scientists to replicate the claim [ 2,3 ] . Normally , such success would have been considered a great achievement . Instead , certain professors\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "source": [
    "# TODO: Define LLM - locally, do NOT use an API\n",
    "\n",
    "llm_model_name = \"google/flan-t5-small\"\n",
    "llm_tokenizer = AutoTokenizer.from_pretrained(llm_model_name)\n",
    "llm_model = AutoModelForSeq2SeqLM.from_pretrained(llm_model_name)\n",
    "llm = pipeline(\"text2text-generation\", model=llm_model, tokenizer=llm_tokenizer)"
   ],
   "metadata": {
    "id": "2cL47Vy4H8Ca",
    "ExecuteTime": {
     "end_time": "2025-03-24T00:39:58.224994Z",
     "start_time": "2025-03-24T00:39:51.239603Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "source": [
    "# TODO: Define a custom prompt that passes the query and the context to the LLM\n",
    "\n",
    "def generate_answer(llm_model, query, context_chunks):\n",
    "  \"\"\"Generates an answer using the locally loaded LLM.\"\"\"\n",
    "  context_text = \"\\n\".join([chunk[\"chunk\"] for chunk in context_chunks])\n",
    "  prompt = f\"Context:\\n{context_text}\\n\\nQuestion: {query}\\nAnswer:\"\n",
    "  response = llm_model(prompt, max_length=200, num_return_sequences=1)\n",
    "  return response"
   ],
   "metadata": {
    "id": "wz5oW6q6ER37",
    "ExecuteTime": {
     "end_time": "2025-03-24T00:40:01.718868Z",
     "start_time": "2025-03-24T00:40:01.716120Z"
    }
   },
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "source": [
    "answer = generate_answer(llm, query1, top_results)\n",
    "print(\"Query:\", query1)\n",
    "print(\"Answer:\", answer)"
   ],
   "metadata": {
    "id": "H0wtBeWQH8Ca",
    "ExecuteTime": {
     "end_time": "2025-03-24T00:40:10.301524Z",
     "start_time": "2025-03-24T00:40:04.190756Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1569 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Who is the founder of NYU?\n",
      "Answer: [{'generated_text': 'Bernhardt Patrick John Mara Bockris'}]\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "source": [
    "# TODO: Repeat the same steps as above for query2 i.e. generate query embedding, get top 5 most-similar chunks and use them to obtain an answer from the LLM\n",
    "\n",
    "query2 = \"What is the difference between Hot and Cold fusion?\"\n",
    "query2_embedding = model.encode([query2]).tolist()\n",
    "top_results = find_similar_chunks(query2_embedding, \"KnowledgeBase.json\", model, top_n=5)\n",
    "\n",
    "answer = generate_answer(llm, query2, top_results)\n",
    "print(\"Query:\", query2)\n",
    "print(\"Answer:\", answer)"
   ],
   "metadata": {
    "id": "txgUcYbLH8Ca",
    "ExecuteTime": {
     "end_time": "2025-03-24T00:41:01.505352Z",
     "start_time": "2025-03-24T00:41:00.183286Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is the difference between Hot and Cold fusion?\n",
      "Answer: [{'generated_text': 'a sprayed layer of palladium'}]\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "b5jfNGiWH8Cb"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Task 3"
   ],
   "metadata": {
    "id": "HyzGwrf7Fa9r"
   }
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T00:47:54.035970Z",
     "start_time": "2025-03-24T00:47:54.031824Z"
    }
   },
   "cell_type": "code",
   "source": "from langchain_core.documents import Document",
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "source": [
    "# We are using the GEMINI API to try out a pre-trained model with billions of params\n",
    "# TODO: Setup the Gemini API using the Gemini and Gemini LangChain links shared the HW PDF\n",
    "# Once setup insert your API Key below\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyCLZTVy9fMmd9QpoTkvKOlVUjcpzKjgEQA\""
   ],
   "metadata": {
    "id": "OVbsehMkH8Cb",
    "ExecuteTime": {
     "end_time": "2025-03-24T00:43:23.397552Z",
     "start_time": "2025-03-24T00:43:23.394237Z"
    }
   },
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "source": [
    "# Initialize the embedding model via Langchain\n",
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': False}\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")\n",
    "\n",
    "# TODO: Load extracted text from the text files you had stored\n",
    "docs = []\n",
    "for filename in os.listdir(\"Docs_Txt\"):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        loader = TextLoader(os.path.join(\"Docs_Txt\", filename), encoding='utf-8')\n",
    "        docs.extend(loader.load())\n",
    "\n",
    "# TODO: Chunk the documents with arguments for size and overlap\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=10)\n",
    "texts = text_splitter.split_documents(docs)\n",
    "\n",
    "# Create the vector store with ChromaDB to create our knowledge base DB in a presisting folder\n",
    "db = Chroma(\n",
    "    collection_name=\"example_collection\",\n",
    "    embedding_function=embedding_model,\n",
    "    persist_directory=\"./chroma_langchain_db\",  # Where to save data locally, remove if not necessary\n",
    ")\n",
    "\n",
    "def chunked(iterable, size):\n",
    "    \"\"\"Helper function to split list into chunks of given size\"\"\"\n",
    "    for i in range(0, len(iterable), size):\n",
    "        yield iterable[i:i + size]\n",
    "        \n",
    "max_batch_size = 5461\n",
    "\n",
    "# Split your texts into smaller batches and add them one by one\n",
    "for batch in chunked(texts, max_batch_size):\n",
    "    db.add_documents(documents=batch)\n"
   ],
   "metadata": {
    "id": "tnQ6nFWOH8Cb",
    "ExecuteTime": {
     "end_time": "2025-03-24T00:51:31.683117Z",
     "start_time": "2025-03-24T00:50:52.257364Z"
    }
   },
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "source": [
    "# TODO: Initialize the LLM pipeline for Gemini via Langchain, and set the initializing parameters for temperature, max_tokens etc.\n",
    "llm = llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash-8b\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2\n",
    ")\n",
    "\n",
    "# TODO: Define a custom prompt template to pass the query and context to the LLM\n",
    "# Note that Larger models such as Gemini are more capable at following instructions specified in the prompt\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    ")\n",
    "# Create the RAG chain with the knowledge base and the prompt\n",
    "qa_chain = RetrievalQA.from_llm(\n",
    "    llm, retriever=db.as_retriever(), prompt=prompt_template\n",
    ")"
   ],
   "metadata": {
    "id": "w4S02kNVH8Cc",
    "ExecuteTime": {
     "end_time": "2025-03-24T00:51:44.261265Z",
     "start_time": "2025-03-24T00:51:44.227707Z"
    }
   },
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "source": [
    "# Testing both queries with the Langchain RAG setup\n",
    "\n",
    "print(query1)\n",
    "print(qa_chain({\"query\": query1}))\n",
    "\n",
    "print(query2)\n",
    "print(qa_chain({\"query\": query2}))"
   ],
   "metadata": {
    "id": "S9hGrTc1H8Cc",
    "ExecuteTime": {
     "end_time": "2025-03-24T00:51:48.761978Z",
     "start_time": "2025-03-24T00:51:47.453212Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who is the founder of NYU?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5r/l6763p1n6ml_4wk4cqxj_lqm0000gn/T/ipykernel_39180/30161837.py:4: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  print(qa_chain({\"query\": query1}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'Who is the founder of NYU?', 'result': \"Don't know.\"}\n",
      "What is the difference between Hot and Cold fusion?\n",
      "{'query': 'What is the difference between Hot and Cold fusion?', 'result': \"I don't know.  The provided texts describe differences, but don't explicitly state *what* the differences are.\"}\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "Vv5IAO1RH8Cc"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
